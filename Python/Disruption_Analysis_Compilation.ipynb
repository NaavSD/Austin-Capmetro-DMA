{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66fe094",
   "metadata": {},
   "source": [
    "# Disruption Analysis Compilation\n",
    "\n",
    "#### File preparation for ArcGIS Analysis\n",
    "\n",
    "Here we will prepare original source Vehicle Location History files for disruption analysis in ArcGIS with the workflow outlined below:\n",
    "\n",
    "- import and slice CSV file(s) to result in dataframe with only relevant fields to analysis.\n",
    "- Construct dataframe datetime fields\n",
    "- Construct disruption index functions for generating a disruption index field in the dataframe.\n",
    "- Export the dataframe to a new CSV file for spatial analysis in GIS.\n",
    "\n",
    "The processes will be outlined in more detail in their own sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcdc1688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956dda08",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "File data will be imported from CSVs provided by Michael Long at Capital Metropolitan Transportation Authority. Initial data will not be provided and subsequent data will be stripped of identifiers for bus and driver identification. The only relevant data for our analysis lies in the headway time of vehicles, and time and location of record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024c8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up path vars.\n",
    "path = r'../00_Source_Data/Capital_Metro/Vehicle_Location_History' # Relative source file path\n",
    "all_files = glob.glob(os.path.join(path , \"*.csv\")) # all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad42ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block generates a list of dataframes where each item in the list is one file.\n",
    "li = []\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore') # ignore dataframe generation warnings\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a48107",
   "metadata": {},
   "source": [
    "## Construct the Dataframe\n",
    "\n",
    "We concatenate the list of dataframes from all files in the `Vehicle_Location_History` folder into a single dataframe and slice that dataframe to contain just the information we need for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7016b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block generates a dataframe with all data from the files stored in the source file path.\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9955f210",
   "metadata": {},
   "source": [
    "#### Formatting the Dataframe\n",
    "\n",
    "The new dataframe we're interested in only needs the following fields:\n",
    "- **timecentral**: Datetime at CST formatted as YYYYMMHHmmssss\n",
    "- **nextstopid**: ID for the next stop along the route\n",
    "- **lat**: Latitude the reading was taken at in WKID 4326 or WGS 1984\n",
    "- **lon**: Longitude the reading was taken at in WKID 4326 or WGS 1984\n",
    "- **headwaysecs**: Headway reading in seconds\n",
    "- **scheduledheadwaysecs**: Planned headway in seconds\n",
    "\n",
    "Fields that will be added later will be explained in the Disruption Index section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e1fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Var for our route of interest and the frequency we'll sample at.\n",
    "## The top five routes for amount of data are the 801, 10, 803, 7, and the 20.\n",
    "route = 20.0\n",
    "freq = '1min'\n",
    "\n",
    "# aggregation columns\n",
    "on = 'timecentral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b7b81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving just the fields we're interested in and removing the original data from memory.\n",
    "\n",
    "# columns we're interested in:\n",
    "cols = ['timecentral', 'nextstopid', 'lat', 'lon', 'headwaysecs', 'scheduledheadwaysecs']\n",
    "li = frame.columns.to_list()\n",
    "\n",
    "#creating a list of the columns we do not want\n",
    "for col in cols:\n",
    "    li.pop(li.index(col))\n",
    "    \n",
    "# Copying just one route's data into our dataframe\n",
    "data = frame[frame['routeid'] == route]\n",
    "\n",
    "# Dropping columns we don't want\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore') # ignore dataframe generation warnings\n",
    "    data.drop(li, axis=1, inplace=True)\n",
    "del frame, li, path, all_files, df, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13cd6e4",
   "metadata": {},
   "source": [
    "#### Converting to Datetime\n",
    "\n",
    "Our current time field is formatted as an integer. In order to use the time values we will want to convert them into a datetime object. The current format is `20220625185013`: \\\n",
    "`2022` - `%Y` Year with century as a decimal \\\n",
    "`06`   - `%m` Month as a zero-padded decimal \\\n",
    "`25`   - `%d` Day of the month as a zero-padded decimal \\\n",
    "`18`   - `%H` Hour (24-hour clock) as a zero-padded decimal \\\n",
    "`50`   - `%M` Minute as a zero-padded decimal \\\n",
    "`13`   - `%S` Second as a zero-padded decimal\n",
    "\n",
    "So the format to change into datetime is `%Y%m%d%H%M%S`\n",
    "\n",
    "We can aggregate the records of the data in the requested time intervals, taking the mean location (`lat`, `lon`), mean headway values (`headwaysecs`) and the mean `disruption index` later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a14678",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254   2022-06-19 00:00:01\n",
       "255   2022-06-19 00:00:21\n",
       "256   2022-06-19 00:00:51\n",
       "259   2022-06-19 00:00:44\n",
       "261   2022-06-19 00:00:24\n",
       "Name: timecentral, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets convert the integer times into datetime objects\n",
    "\n",
    "data['timecentral'] = pd.to_datetime(data['timecentral'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "data['timecentral'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "987e8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove rows with NaN values for `headwaysecs` as they will not be useful for our analysis\n",
    "\n",
    "data = data[data['headwaysecs'].notna()]\n",
    "data = data[data['scheduledheadwaysecs'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc10c3e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5720.7 , 0.1\n"
     ]
    }
   ],
   "source": [
    "print(data[['headwaysecs']].max()[0],',', data[['headwaysecs']].min()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6bfcf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860.0 , 180.0\n"
     ]
    }
   ],
   "source": [
    "print(data[['scheduledheadwaysecs']].max()[0],',', data[['scheduledheadwaysecs']].min()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3febeb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    225888\n",
      "Name: headwaysecs, dtype: int64\n",
      "False    225888\n",
      "Name: scheduledheadwaysecs, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure it worked\n",
    "print(data['headwaysecs'].isna().value_counts())\n",
    "print(data['scheduledheadwaysecs'].isna().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada572e",
   "metadata": {},
   "source": [
    "## Construct Disruption Index\n",
    "\n",
    "In this section, we will create new fields for the disruption indices and calculate them based on the work of Federico Malucelli and Emanuele Tresoldi in their case study. DOI: [s12469-019-00196-y](https://link.springer.com/article/10.1007/s12469-019-00196-y)\n",
    "\n",
    "The fields we will construct are: \\\n",
    "`HR`     - Headway Ratio: the ratio between the observed headway and the planned one. \\\n",
    "`HS`     - Headway Standard Deviation: standard deviation of the difference between the observed and the planned headways \\\n",
    "`PR`     - Percentage Regularity Deviation: the percentage average ratio between the deviation of the observed headway from the planned one and the planned headway. \\\n",
    "`PW`     - Piece-wise linear regularity index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff47963",
   "metadata": {},
   "source": [
    "First, we will define a frequency with which to do our sampling. For a list of the appropriate strings to enter into the frequency variable please see [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96b755de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nextstopid</th>\n",
       "      <th>headwaysecs</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>scheduledheadwaysecs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timecentral</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:00:00</th>\n",
       "      <td>5965.0</td>\n",
       "      <td>1722.966667</td>\n",
       "      <td>30.287637</td>\n",
       "      <td>-97.709945</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:01:00</th>\n",
       "      <td>5965.0</td>\n",
       "      <td>1712.375000</td>\n",
       "      <td>30.290038</td>\n",
       "      <td>-97.705720</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:02:00</th>\n",
       "      <td>2607.0</td>\n",
       "      <td>1641.275000</td>\n",
       "      <td>30.294023</td>\n",
       "      <td>-97.703555</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:03:00</th>\n",
       "      <td>1604.0</td>\n",
       "      <td>1657.050000</td>\n",
       "      <td>30.295455</td>\n",
       "      <td>-97.700085</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:04:00</th>\n",
       "      <td>5940.0</td>\n",
       "      <td>1645.600000</td>\n",
       "      <td>30.295490</td>\n",
       "      <td>-97.698025</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:55:00</th>\n",
       "      <td>4326.0</td>\n",
       "      <td>1983.950000</td>\n",
       "      <td>30.265249</td>\n",
       "      <td>-97.697847</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:56:00</th>\n",
       "      <td>5616.0</td>\n",
       "      <td>1938.822222</td>\n",
       "      <td>30.264969</td>\n",
       "      <td>-97.701893</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:57:00</th>\n",
       "      <td>6289.0</td>\n",
       "      <td>1970.611111</td>\n",
       "      <td>30.281550</td>\n",
       "      <td>-97.694847</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:58:00</th>\n",
       "      <td>6289.0</td>\n",
       "      <td>1858.028571</td>\n",
       "      <td>30.285206</td>\n",
       "      <td>-97.707611</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:59:00</th>\n",
       "      <td>4524.0</td>\n",
       "      <td>1929.788889</td>\n",
       "      <td>30.289093</td>\n",
       "      <td>-97.698702</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10080 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nextstopid  headwaysecs        lat        lon  \\\n",
       "timecentral                                                          \n",
       "2022-06-19 00:00:00      5965.0  1722.966667  30.287637 -97.709945   \n",
       "2022-06-19 00:01:00      5965.0  1712.375000  30.290038 -97.705720   \n",
       "2022-06-19 00:02:00      2607.0  1641.275000  30.294023 -97.703555   \n",
       "2022-06-19 00:03:00      1604.0  1657.050000  30.295455 -97.700085   \n",
       "2022-06-19 00:04:00      5940.0  1645.600000  30.295490 -97.698025   \n",
       "...                         ...          ...        ...        ...   \n",
       "2022-06-25 23:55:00      4326.0  1983.950000  30.265249 -97.697847   \n",
       "2022-06-25 23:56:00      5616.0  1938.822222  30.264969 -97.701893   \n",
       "2022-06-25 23:57:00      6289.0  1970.611111  30.281550 -97.694847   \n",
       "2022-06-25 23:58:00      6289.0  1858.028571  30.285206 -97.707611   \n",
       "2022-06-25 23:59:00      4524.0  1929.788889  30.289093 -97.698702   \n",
       "\n",
       "                     scheduledheadwaysecs  \n",
       "timecentral                                \n",
       "2022-06-19 00:00:00                1800.0  \n",
       "2022-06-19 00:01:00                1800.0  \n",
       "2022-06-19 00:02:00                1800.0  \n",
       "2022-06-19 00:03:00                1800.0  \n",
       "2022-06-19 00:04:00                1800.0  \n",
       "...                                   ...  \n",
       "2022-06-25 23:55:00                1800.0  \n",
       "2022-06-25 23:56:00                1800.0  \n",
       "2022-06-25 23:57:00                1800.0  \n",
       "2022-06-25 23:58:00                1800.0  \n",
       "2022-06-25 23:59:00                1800.0  \n",
       "\n",
       "[10080 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the left side of the dataframe grouped in the chosen interval. \n",
    "# This will be concatenated with the calculated fields later and serve as the master dataframe that we'll export later.\n",
    "\n",
    "master_1 = data[['nextstopid', 'timecentral']].resample(freq, on=on).max()\n",
    "master_2 = data.groupby(pd.Grouper(key='timecentral', freq=freq)).mean()\n",
    "master_1.drop(columns='timecentral', axis=1, inplace=True)\n",
    "master_2.drop(columns='nextstopid', axis=1, inplace=True)\n",
    "\n",
    "master_df = pd.concat([master_1, master_2], axis=1)\n",
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9cfbe3",
   "metadata": {},
   "source": [
    "#### Headway Statistic Functions\n",
    "\n",
    "Lets start by making the function that will generate the three statistical fields for our dataframe. These functions are as follows:\n",
    "$$ HR=1-\\bigg | \\dfrac{\\sum_{q \\in P} \\dfrac{v_o (q)}{v_e (q)}}{|P|} -1 \\bigg | = 1-\\bigg | \\dfrac{\\sum_{\\text{interval}} \\text{ratio}}{\\text{records in interval}} -1 \\bigg |\\\\\n",
    "HS=1- \\dfrac{\\text{std({$v_o (q), \\forall q \\in P$})}}{\\text{avg({$v_e (q), \\forall q \\in P$})}} \\\\\n",
    "PR=1- \\dfrac{\\sum_{q \\in P} \\dfrac{|v_o (q) - v_e (q)|}{v_e (q)}}{|P|} = 1- \\dfrac{\\sum_{\\text{interval}} \\dfrac{|\\text{gap}|}{v_e (q)}}{\\text{records in interval}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eef74b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here we will do our calculations for the HR function.\n",
    "\n",
    "# Generate intermediate calculations.\n",
    "data['gap'] = data['headwaysecs'] - data['scheduledheadwaysecs']\n",
    "data['ratio'] = data['headwaysecs']/data['scheduledheadwaysecs']\n",
    "    \n",
    "# define new dataframes\n",
    "data_0 = pd.DataFrame() \n",
    "data_1 = pd.DataFrame()\n",
    "data_2 = pd.DataFrame()\n",
    "    \n",
    "li = data.columns.to_list()\n",
    "li.pop(li.index('timecentral'))\n",
    "\n",
    "# Sum ratios by time freq\n",
    "data_1 = data.resample(freq, on=on).sum()\n",
    "li.pop(li.index('ratio'))\n",
    "data_1.drop(li, axis=1, inplace=True)\n",
    "    \n",
    "# Generate a count of elements in the aggregate.\n",
    "data_2 = data.resample(freq, on=on).count()\n",
    "data_2.drop(li, axis=1, inplace=True)\n",
    "data_2.rename(columns = {'ratio':'count'}, inplace=True)\n",
    "\n",
    "# Calculate the headway ratio 'HR'\n",
    "data_0['HR'] = 1-abs((data_1['ratio']/data_2['count'])-1)\n",
    "\n",
    "# Now we can concatenate our HR value to the master list and remove our intermediate dataframes from memory.\n",
    "master_df = pd.concat([master_df, data_0], axis=1)\n",
    "del data_0, data_1, data_2, li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44570bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will do our calculations for the HS function.\n",
    "\n",
    "# define new dataframes\n",
    "data_0 = pd.DataFrame() \n",
    "data_1 = pd.DataFrame()\n",
    "data_2 = pd.DataFrame()\n",
    "\n",
    "\n",
    "li = data.columns.to_list()\n",
    "li.pop(li.index('timecentral'))\n",
    "\n",
    "# Calculate deviation within intervals of headway\n",
    "data_1 = data.resample(freq, on=on).std()\n",
    "li.pop(li.index('headwaysecs'))\n",
    "data_1.drop(li, axis=1, inplace=True)\n",
    "data_1.rename(columns={'headwaysecs':'o_std'}, inplace=True)\n",
    "\n",
    "# refresh column list\n",
    "li = data.columns.to_list()\n",
    "li.pop(li.index('timecentral'))\n",
    "\n",
    "# Calculate average of expected headways within intervals\n",
    "data_2 = data.resample(freq, on=on).mean()\n",
    "li.pop(li.index('scheduledheadwaysecs'))\n",
    "data_2.drop(li, axis=1, inplace=True)\n",
    "data_2.rename(columns={'scheduledheadwaysecs':'e_avg'}, inplace=True)\n",
    "\n",
    "# Run the HS calculation\n",
    "data_0['HS'] = 1-(data_1['o_std']/data_2['e_avg'])\n",
    "\n",
    "# Concatenate HS values to master dataframe and delete intermediate variables from memory\n",
    "master_df = pd.concat([master_df, data_0], axis=1)\n",
    "del data_0, data_1, data_2, li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4d4d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will do our calculations for the PR function.\n",
    "\n",
    "# define new dataframes\n",
    "data_0 = pd.DataFrame() \n",
    "data_1 = pd.DataFrame()\n",
    "data_1_1 = pd.DataFrame()\n",
    "data_2 = pd.DataFrame()\n",
    "\n",
    "# First, we need to calculate our gap/expected-headway\n",
    "data_1_1 = data\n",
    "data_1_1['gap_expected'] = data_1_1['gap']/data_1_1['scheduledheadwaysecs']\n",
    "\n",
    "li = data_1_1.columns.to_list()\n",
    "li.pop(li.index('timecentral'))\n",
    "\n",
    "# Sum the resulting gap_expected for our numerator\n",
    "data_1 = data_1_1.resample(freq, on=on).sum()\n",
    "li.pop(li.index('gap_expected'))\n",
    "data_1.drop(li, axis=1, inplace=True)\n",
    "\n",
    "# calculate records in interval 'P'\n",
    "data_2 = data.resample(freq, on=on).count()\n",
    "data_2.drop(li, axis=1, inplace=True)\n",
    "data_2.rename(columns = {'gap_expected':'count'}, inplace=True)\n",
    "\n",
    "# Calculate PR\n",
    "data_0['PR'] = 1- (data_1['gap_expected']/data_2['count'])\n",
    "\n",
    "# Concatenate HS values to master dataframe and delete intermediate variables from memory\n",
    "master_df = pd.concat([master_df, data_0], axis=1)\n",
    "del data_0, data_1, data_2, li, data_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4f058",
   "metadata": {},
   "source": [
    "Lets consider the gap $x(q)$ in the planned $(v_e (q))$ and observed $(v_o (q))$ headways:\n",
    "$$ x(q) = v_o (q) - v_e (q) $$\n",
    "\n",
    "A negative value is an early pass and a positive value is a delay.\n",
    "\n",
    "Malucelli and Tresoldi then define the function of $f(x(q))$ of the gap as:\n",
    "$$\n",
    "f(x(q))=\n",
    "\\begin{cases}\n",
    "-\\alpha x(q) & \\quad \\text{if $x(q) < -\\theta_1$}\\\\\n",
    "0 & \\quad \\text{if $-\\theta_1 \\leq x(q) < \\theta_2$}\\\\\n",
    "\\beta x(q) & \\quad \\text{if $\\theta_2 \\leq x(q) < \\theta_3$}\\\\\n",
    "\\gamma x(q)+\\delta & \\quad \\text{if $\\theta_3 \\leq x(q)$}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where $\\theta_1$, $\\theta_2$, $\\theta_3$ and $\\alpha, \\beta, \\gamma, \\delta$ are suitable parameters. The function is 0 if the pass is regular and is not 0 if the pass is irregular. We can ignore contributions of earliness on the index by setting $\\alpha = 0$. Likewise, if we set all coefficients to 0 and $\\delta = 1$ we are left with the simple index the Azienda Trasporti Milanesi used at the writing of their paper. Values where $x(q) \\geq \\theta_3$ are intended to penalize large gaps more than the equivlent sum of small gaps.\n",
    "\n",
    "Thus the index of regularity based on Malucelli and Tresoldi's piece-wise function is:\n",
    "$$\n",
    "I(PW)= \\sum_{q \\in P} f(x(q))\n",
    "$$\n",
    "\n",
    "Where $P$ is the set of all passes in a given period.\n",
    "\n",
    "In consideration of time, we will only be constructing the piece-wise function from Malucelli and Tresoldi and using its related index for the purposes of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e1baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will calculate the Malucelli-Tresoldi Piecewise Index for the intervals.\n",
    "\n",
    "# define new dataframes\n",
    "data_0 = pd.DataFrame() \n",
    "\n",
    "# define a function for the conditions of the piecewise function.\n",
    "# Our default parameters will be equal to the simplist function. Labeled as 01 by Malucelli and Tresoldi.\n",
    "def piecewise(X, a=0, b=0, g=0, d=1, t_1=120, t_2=120, t_3=240):\n",
    "    if X < -t_1:\n",
    "        return -a*X\n",
    "    elif X >= -t_1 and X < t_2:\n",
    "        return 0\n",
    "    elif X >= t_2 and X < t_3:\n",
    "        return b*X\n",
    "    elif X >= t_3:\n",
    "        return g*X+d\n",
    "\n",
    "# apply our piecewise function\n",
    "li = []\n",
    "for row in data.itertuples():\n",
    "    gap = row.gap\n",
    "    pw = piecewise(gap)\n",
    "    li.append(pw)\n",
    "data['PW'] = li\n",
    "\n",
    "# Create a list of columns for data_1 to drop later.\n",
    "li = data.columns.to_list()\n",
    "li.pop(li.index('timecentral'))\n",
    "\n",
    "# Sum our 'PW' values by our intervals to get our index\n",
    "data_0 = data.resample(freq, on=on).sum()\n",
    "li.pop(li.index('PW')) # We want to keep the 'PW' column\n",
    "data_0.drop(li, axis=1, inplace=True)\n",
    "data_0.rename(columns={'PW':'I_PW'}, inplace=True)\n",
    "\n",
    "# Concatenate I_PW values to master dataframe and delete intermediate variables from memory\n",
    "master_df = pd.concat([master_df, data_0], axis=1)\n",
    "del data_0, li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8575196d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nextstopid</th>\n",
       "      <th>headwaysecs</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>scheduledheadwaysecs</th>\n",
       "      <th>HR</th>\n",
       "      <th>HS</th>\n",
       "      <th>PR</th>\n",
       "      <th>I_PW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timecentral</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:00:00</th>\n",
       "      <td>5965.0</td>\n",
       "      <td>1722.966667</td>\n",
       "      <td>30.287637</td>\n",
       "      <td>-97.709945</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.957204</td>\n",
       "      <td>0.941931</td>\n",
       "      <td>1.042796</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:01:00</th>\n",
       "      <td>5965.0</td>\n",
       "      <td>1712.375000</td>\n",
       "      <td>30.290038</td>\n",
       "      <td>-97.705720</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.951319</td>\n",
       "      <td>0.964636</td>\n",
       "      <td>1.048681</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:02:00</th>\n",
       "      <td>2607.0</td>\n",
       "      <td>1641.275000</td>\n",
       "      <td>30.294023</td>\n",
       "      <td>-97.703555</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.911819</td>\n",
       "      <td>0.957788</td>\n",
       "      <td>1.088181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:03:00</th>\n",
       "      <td>1604.0</td>\n",
       "      <td>1657.050000</td>\n",
       "      <td>30.295455</td>\n",
       "      <td>-97.700085</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.920583</td>\n",
       "      <td>0.938050</td>\n",
       "      <td>1.079417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:04:00</th>\n",
       "      <td>5940.0</td>\n",
       "      <td>1645.600000</td>\n",
       "      <td>30.295490</td>\n",
       "      <td>-97.698025</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.914222</td>\n",
       "      <td>0.948184</td>\n",
       "      <td>1.085778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:55:00</th>\n",
       "      <td>4326.0</td>\n",
       "      <td>1983.950000</td>\n",
       "      <td>30.265249</td>\n",
       "      <td>-97.697847</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.897806</td>\n",
       "      <td>0.529081</td>\n",
       "      <td>0.897806</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:56:00</th>\n",
       "      <td>5616.0</td>\n",
       "      <td>1938.822222</td>\n",
       "      <td>30.264969</td>\n",
       "      <td>-97.701893</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.922877</td>\n",
       "      <td>0.549613</td>\n",
       "      <td>0.922877</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:57:00</th>\n",
       "      <td>6289.0</td>\n",
       "      <td>1970.611111</td>\n",
       "      <td>30.281550</td>\n",
       "      <td>-97.694847</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.905216</td>\n",
       "      <td>0.444576</td>\n",
       "      <td>0.905216</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:58:00</th>\n",
       "      <td>6289.0</td>\n",
       "      <td>1858.028571</td>\n",
       "      <td>30.285206</td>\n",
       "      <td>-97.707611</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.967762</td>\n",
       "      <td>0.462787</td>\n",
       "      <td>0.967762</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:59:00</th>\n",
       "      <td>4524.0</td>\n",
       "      <td>1929.788889</td>\n",
       "      <td>30.289093</td>\n",
       "      <td>-97.698702</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.927895</td>\n",
       "      <td>0.421829</td>\n",
       "      <td>0.927895</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10080 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nextstopid  headwaysecs        lat        lon  \\\n",
       "timecentral                                                          \n",
       "2022-06-19 00:00:00      5965.0  1722.966667  30.287637 -97.709945   \n",
       "2022-06-19 00:01:00      5965.0  1712.375000  30.290038 -97.705720   \n",
       "2022-06-19 00:02:00      2607.0  1641.275000  30.294023 -97.703555   \n",
       "2022-06-19 00:03:00      1604.0  1657.050000  30.295455 -97.700085   \n",
       "2022-06-19 00:04:00      5940.0  1645.600000  30.295490 -97.698025   \n",
       "...                         ...          ...        ...        ...   \n",
       "2022-06-25 23:55:00      4326.0  1983.950000  30.265249 -97.697847   \n",
       "2022-06-25 23:56:00      5616.0  1938.822222  30.264969 -97.701893   \n",
       "2022-06-25 23:57:00      6289.0  1970.611111  30.281550 -97.694847   \n",
       "2022-06-25 23:58:00      6289.0  1858.028571  30.285206 -97.707611   \n",
       "2022-06-25 23:59:00      4524.0  1929.788889  30.289093 -97.698702   \n",
       "\n",
       "                     scheduledheadwaysecs        HR        HS        PR  I_PW  \n",
       "timecentral                                                                    \n",
       "2022-06-19 00:00:00                1800.0  0.957204  0.941931  1.042796   0.0  \n",
       "2022-06-19 00:01:00                1800.0  0.951319  0.964636  1.048681   0.0  \n",
       "2022-06-19 00:02:00                1800.0  0.911819  0.957788  1.088181   0.0  \n",
       "2022-06-19 00:03:00                1800.0  0.920583  0.938050  1.079417   0.0  \n",
       "2022-06-19 00:04:00                1800.0  0.914222  0.948184  1.085778   0.0  \n",
       "...                                   ...       ...       ...       ...   ...  \n",
       "2022-06-25 23:55:00                1800.0  0.897806  0.529081  0.897806   3.0  \n",
       "2022-06-25 23:56:00                1800.0  0.922877  0.549613  0.922877   2.0  \n",
       "2022-06-25 23:57:00                1800.0  0.905216  0.444576  0.905216   3.0  \n",
       "2022-06-25 23:58:00                1800.0  0.967762  0.462787  0.967762   2.0  \n",
       "2022-06-25 23:59:00                1800.0  0.927895  0.421829  0.927895   3.0  \n",
       "\n",
       "[10080 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ef304",
   "metadata": {},
   "source": [
    "## Export Dataframe\n",
    "\n",
    "The last thing to do is export the dataframe for spatial analysis in ArcGIS Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a8b7898",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv(\"../01_New_Data/Python_Output/Route_\"+str(route)+\"_Disruption.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c419a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
