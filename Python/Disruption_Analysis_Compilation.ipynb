{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66fe094",
   "metadata": {},
   "source": [
    "# Disruption Analysis Compilation\n",
    "\n",
    "#### File preparation for ArcGIS Analysis\n",
    "\n",
    "Here we will prepare original source Vehicle Location History files for disruption analysis in ArcGIS with the workflow outlined below:\n",
    "\n",
    "- import and slice CSV file(s) to result in dataframe with only relevant fields to analysis.\n",
    "- Construct dataframe datetime fields\n",
    "- Construct disruption index functions for generating a disruption index field in the dataframe.\n",
    "- Export the dataframe to a new CSV file for spatial analysis in GIS.\n",
    "\n",
    "The processes will be outlined in more detail in their own sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcdc1688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956dda08",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "File data will be imported from CSVs provided by Michael Long at Capital Metropolitan Transportation Authority. Initial data will not be provided and subsequent data will be stripped of identifiers for bus and driver identification. The only relevant data for our analysis lies in the headway time of vehicles, and time and location of record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024c8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up path vars.\n",
    "path = r'../00_Source_Data/Capital_Metro/Vehicle_Location_History' # Relative source file path\n",
    "all_files = glob.glob(os.path.join(path , \"*.csv\")) # all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad42ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block generates a list of dataframes where each item in the list is one file.\n",
    "li = []\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore') # ignore dataframe generation warnings\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a48107",
   "metadata": {},
   "source": [
    "## Construct the Dataframe\n",
    "\n",
    "We concatenate the list of dataframes from all files in the `Vehicle_Location_History` folder into a single dataframe and slice that dataframe to contain just the information we need for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7016b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block generates a dataframe with all data from the files stored in the source file path.\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9955f210",
   "metadata": {},
   "source": [
    "#### Formatting the Dataframe\n",
    "\n",
    "The new dataframe we're interested in only needs the following fields:\n",
    "- **timecentral**: Datetime at CST formatted as YYYYMMHHmmssss\n",
    "- **lat**: Latitude the reading was taken at in WKID 4326 or WGS 1984\n",
    "- **lon**: Longitude the reading was taken at in WKID 4326 or WGS 1984\n",
    "- **headwaysecs**: Headway reading in seconds\n",
    "- **scheduledheadwaysecs**: Planned headway in seconds\n",
    "\n",
    "Fields that will be added later will be explained in the Disruption Index section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7b81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving just the fields we're interested in and removing the original data from memory.\n",
    "data = frame[['timecentral', 'lat', 'lon', 'headwaysecs', 'scheduledheadwaysecs']]\n",
    "del frame, li, path, all_files, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13cd6e4",
   "metadata": {},
   "source": [
    "#### Converting to Datetime\n",
    "\n",
    "Our current time field is formatted as an integer. In order to use the time values we will want to convert them into a datetime object. The current format is `20220625185013`: \\\n",
    "`2022` - `%Y` Year with century as a decimal \\\n",
    "`06`   - `%m` Month as a zero-padded decimal \\\n",
    "`25`   - `%d` Day of the month as a zero-padded decimal \\\n",
    "`18`   - `%H` Hour (24-hour clock) as a zero-padded decimal \\\n",
    "`50`   - `%M` Minute as a zero-padded decimal \\\n",
    "`13`   - `%S` Second as a zero-padded decimal\n",
    "\n",
    "So the format to change into datetime is `%Y%m%d%H%M%S`\n",
    "\n",
    "We can aggregate the records of the data in the requested time intervals, taking the mean location (`lat`, `lon`), mean headway values (`headwaysecs`) and the mean `disruption index` later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a14678",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2022-06-19 00:00:23\n",
       "1   2022-06-19 00:00:03\n",
       "2   2022-06-19 00:00:16\n",
       "3   2022-06-19 00:00:48\n",
       "4   2022-06-19 00:00:43\n",
       "Name: timecentral, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets convert the integer times into datetime objects\n",
    "\n",
    "data['timecentral'] = pd.to_datetime(data['timecentral'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "data['timecentral'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987e8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove rows with NaN values for `headwaysecs` as they will not be useful for our analysis\n",
    "\n",
    "data = data[data['headwaysecs'].notna()]\n",
    "data = data[data['scheduledheadwaysecs'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc10c3e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7199.8 , 0.0\n"
     ]
    }
   ],
   "source": [
    "print(data[['headwaysecs']].max()[0],',', data[['headwaysecs']].min()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6bfcf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7680.0 , 34.0\n"
     ]
    }
   ],
   "source": [
    "print(data[['scheduledheadwaysecs']].max()[0],',', data[['scheduledheadwaysecs']].min()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3febeb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    4129586\n",
      "Name: headwaysecs, dtype: int64\n",
      "False    4129586\n",
      "Name: scheduledheadwaysecs, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure it worked\n",
    "print(data['headwaysecs'].isna().value_counts())\n",
    "print(data['scheduledheadwaysecs'].isna().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada572e",
   "metadata": {},
   "source": [
    "## Construct Disruption Index\n",
    "\n",
    "In this section, we will create new fields for the disruption indices and calculate them based on the work of Federico Malucelli and Emanuele Tresoldi in their case study. DOI: [s12469-019-00196-y](https://link.springer.com/article/10.1007/s12469-019-00196-y)\n",
    "\n",
    "The fields we will construct are: \\\n",
    "`HR`     - Headway Ratio: the ratio between the observed headway and the planned one. \\\n",
    "`HS`     - Headway Standard Deviation: standard deviation of the difference between the observed and the planned headways \\\n",
    "`PR`     - Percentage Regularity Deviation: the percentage average ratio between the deviation of the observed headway from the planned one and the planned headway. \\\n",
    "`PW`     - Piece-wise linear regularity index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff47963",
   "metadata": {},
   "source": [
    "First, we will define a frequency with which to do our sampling. For a list of the appropriate strings to enter into the frequency variable please see [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb360bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a frequency to sample the data with.\n",
    "freq='H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96b755de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>headwaysecs</th>\n",
       "      <th>scheduledheadwaysecs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timecentral</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:00:00</th>\n",
       "      <td>30.293191</td>\n",
       "      <td>-97.737928</td>\n",
       "      <td>1687.359947</td>\n",
       "      <td>1693.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 01:00:00</th>\n",
       "      <td>30.295484</td>\n",
       "      <td>-97.738471</td>\n",
       "      <td>1686.653455</td>\n",
       "      <td>1715.270608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 02:00:00</th>\n",
       "      <td>30.278059</td>\n",
       "      <td>-97.737004</td>\n",
       "      <td>1732.625760</td>\n",
       "      <td>1692.547033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 03:00:00</th>\n",
       "      <td>30.279623</td>\n",
       "      <td>-97.735773</td>\n",
       "      <td>1741.818209</td>\n",
       "      <td>1710.132159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 19:00:00</th>\n",
       "      <td>30.291210</td>\n",
       "      <td>-97.732976</td>\n",
       "      <td>1465.227817</td>\n",
       "      <td>1405.872931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 20:00:00</th>\n",
       "      <td>30.292363</td>\n",
       "      <td>-97.732183</td>\n",
       "      <td>1667.768094</td>\n",
       "      <td>1610.051929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 21:00:00</th>\n",
       "      <td>30.292783</td>\n",
       "      <td>-97.734055</td>\n",
       "      <td>1752.594771</td>\n",
       "      <td>1702.955922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 22:00:00</th>\n",
       "      <td>30.292943</td>\n",
       "      <td>-97.735064</td>\n",
       "      <td>1697.509141</td>\n",
       "      <td>1664.296605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:00:00</th>\n",
       "      <td>30.290101</td>\n",
       "      <td>-97.735207</td>\n",
       "      <td>1702.841482</td>\n",
       "      <td>1637.555621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           lat        lon  headwaysecs  scheduledheadwaysecs\n",
       "timecentral                                                                 \n",
       "2022-06-19 00:00:00  30.293191 -97.737928  1687.359947           1693.142857\n",
       "2022-06-19 01:00:00  30.295484 -97.738471  1686.653455           1715.270608\n",
       "2022-06-19 02:00:00  30.278059 -97.737004  1732.625760           1692.547033\n",
       "2022-06-19 03:00:00  30.279623 -97.735773  1741.818209           1710.132159\n",
       "2022-06-19 04:00:00        NaN        NaN          NaN                   NaN\n",
       "...                        ...        ...          ...                   ...\n",
       "2022-06-25 19:00:00  30.291210 -97.732976  1465.227817           1405.872931\n",
       "2022-06-25 20:00:00  30.292363 -97.732183  1667.768094           1610.051929\n",
       "2022-06-25 21:00:00  30.292783 -97.734055  1752.594771           1702.955922\n",
       "2022-06-25 22:00:00  30.292943 -97.735064  1697.509141           1664.296605\n",
       "2022-06-25 23:00:00  30.290101 -97.735207  1702.841482           1637.555621\n",
       "\n",
       "[168 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the left side of the dataframe grouped in the chosen interval. \n",
    "# This will be concatenated with the calculated fields later and serve as the master dataframe that we'll export later.\n",
    "\n",
    "master_df = data.groupby(pd.Grouper(key='timecentral', freq=freq)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9cfbe3",
   "metadata": {},
   "source": [
    "#### Headway Statistic Functions\n",
    "\n",
    "Lets start by making the function that will generate the three statistical fields for our dataframe. These functions are as follows:\n",
    "$$ HR=1-\\bigg | \\dfrac{\\sum_{q \\in P} \\dfrac{v_o (q)}{v_e (q)}}{|P|} -1 \\bigg | = 1-\\bigg | \\dfrac{\\sum_{\\text{interval}} \\text{ratio}}{\\text{records in interval}} -1 \\bigg |\\\\\n",
    "HS=1- \\dfrac{\\text{std({$v_o (q), \\forall q \\in P$})}}{\\text{avg({$v_e (q), \\forall q \\in P$})}} \\\\\n",
    "PR=1- \\dfrac{\\sum_{q \\in P} \\dfrac{|v_o (q) - v_e (q)|}{v_e (q)}}{|P|} = 1- \\dfrac{\\sum_{\\text{interval}} \\dfrac{|\\text{gap}|}{v_e (q)}}{\\text{records in interval}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eef74b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here we will do our calculations for the HR function.\n",
    "\n",
    "# Generate intermediate calculations.\n",
    "data['gap'] = data['headwaysecs'] - data['scheduledheadwaysecs']\n",
    "data['ratio'] = data['headwaysecs']/data['scheduledheadwaysecs']\n",
    "    \n",
    "# define new dataframes\n",
    "data_0 = pd.DataFrame() \n",
    "data_1 = pd.DataFrame()\n",
    "data_2 = pd.DataFrame()\n",
    "    \n",
    "li = data.columns.to_list()\n",
    "li.pop(li.index('timecentral'))\n",
    "\n",
    "# Sum ratios by time freq\n",
    "data_1 = data.resample(freq, on='timecentral').sum()\n",
    "li.pop(li.index('ratio'))\n",
    "data_1.drop(li, axis=1, inplace=True)\n",
    "    \n",
    "# Generate a count of elements in the aggregate.\n",
    "data_2 = data.resample(freq, on='timecentral').count()\n",
    "data_2.drop(li, axis=1, inplace=True)\n",
    "data_2.rename(columns = {'ratio':'count'}, inplace=True)\n",
    "\n",
    "# Calculate the headway ratio 'HR'\n",
    "data_0['HR'] = 1-abs((data_1['ratio']/data_2['count'])-1)\n",
    "\n",
    "# Now we can concatenate our HR value to the master list and remove our intermediate dataframes from memory.\n",
    "master_df = pd.concat([master_df, data_0], axis=1)\n",
    "del data_0, data_1, data_2, li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44570bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will do our calculations for the HS function.\n",
    "\n",
    "# define new dataframes\n",
    "data_0 = pd.DataFrame() \n",
    "data_1 = pd.DataFrame()\n",
    "data_2 = pd.DataFrame()\n",
    "\n",
    "\n",
    "li = data.columns.to_list()\n",
    "li.pop(li.index('timecentral'))\n",
    "\n",
    "# Calculate deviation within intervals of headway\n",
    "data_1 = data.resample(freq, on='timecentral').std()\n",
    "li.pop(li.index('headwaysecs'))\n",
    "data_1.drop(li, axis=1, inplace=True)\n",
    "data_1.rename(columns={'headwaysecs':'o_std'}, inplace=True)\n",
    "\n",
    "# refresh column list\n",
    "li = data.columns.to_list()\n",
    "li.pop(li.index('timecentral'))\n",
    "\n",
    "# Calculate average of expected headways within intervals\n",
    "data_2 = data.resample(freq, on='timecentral').mean()\n",
    "li.pop(li.index('scheduledheadwaysecs'))\n",
    "data_2.drop(li, axis=1, inplace=True)\n",
    "data_2.rename(columns={'scheduledheadwaysecs':'e_avg'}, inplace=True)\n",
    "\n",
    "# Run the HS calculation\n",
    "data_0['HS'] = 1-(data_1['o_std']/data_2['e_avg'])\n",
    "\n",
    "# Concatenate HS values to master dataframe and delete intermediate variables from memory\n",
    "master_df = pd.concat([master_df, data_0], axis=1)\n",
    "del data_0, data_1, data_2, li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4d4d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will do our calculations for the PR function.\n",
    "\n",
    "# define new dataframes\n",
    "data_0 = pd.DataFrame() \n",
    "data_1 = pd.DataFrame()\n",
    "data_1_1 = pd.DataFrame()\n",
    "data_2 = pd.DataFrame()\n",
    "\n",
    "# First, we need to calculate our gap/expected-headway\n",
    "data_1_1 = data\n",
    "data_1_1['gap_expected'] = data_1_1['gap']/data_1_1['scheduledheadwaysecs']\n",
    "\n",
    "li = data_1_1.columns.to_list()\n",
    "li.pop(li.index('timecentral'))\n",
    "\n",
    "# Sum the resulting gap_expected for our numerator\n",
    "data_1 = data_1_1.resample(freq, on='timecentral').sum()\n",
    "li.pop(li.index('gap_expected'))\n",
    "data_1.drop(li, axis=1, inplace=True)\n",
    "\n",
    "# calculate records in interval 'P'\n",
    "data_2 = data.resample(freq, on='timecentral').count()\n",
    "data_2.drop(li, axis=1, inplace=True)\n",
    "data_2.rename(columns = {'gap_expected':'count'}, inplace=True)\n",
    "\n",
    "# Calculate PR\n",
    "data_0['PR'] = 1- (data_1['gap_expected']/data_2['count'])\n",
    "\n",
    "# Concatenate HS values to master dataframe and delete intermediate variables from memory\n",
    "master_df = pd.concat([master_df, data_0], axis=1)\n",
    "del data_0, data_1, data_2, li, data_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4f058",
   "metadata": {},
   "source": [
    "Lets consider the gap $x(q)$ in the planned $(v_e (q))$ and observed $(v_o (q))$ headways:\n",
    "$$ x(q) = v_o (q) - v_e (q) $$\n",
    "\n",
    "A negative value is an early pass and a positive value is a delay.\n",
    "\n",
    "Malucelli and Tresoldi then define the function of $f(x(q))$ of the gap as:\n",
    "$$\n",
    "f(x(q))=\n",
    "\\begin{cases}\n",
    "-\\alpha x(q) & \\quad \\text{if $x(q) < -\\theta_1$}\\\\\n",
    "0 & \\quad \\text{if $-\\theta_1 \\leq x(q) < \\theta_2$}\\\\\n",
    "\\beta x(q) & \\quad \\text{if $\\theta_2 \\leq x(q) < \\theta_3$}\\\\\n",
    "\\gamma x(q)+\\delta & \\quad \\text{if $\\theta_3 \\leq x(q)$}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where $\\theta_1$, $\\theta_2$, $\\theta_3$ and $\\alpha, \\beta, \\gamma, \\delta$ are suitable parameters. The function is 0 if the pass is regular and is not 0 if the pass is irregular. We can ignore contributions of earliness on the index by setting $\\alpha = 0$. Likewise, if we set all coefficients to 0 and $\\delta = 1$ we are left with the simple index the Azienda Trasporti Milanesi used at the writing of their paper. Values where $x(q) \\geq \\theta_3$ are intended to penalize large gaps more than the equivlent sum of small gaps.\n",
    "\n",
    "Thus the index of regularity based on Malucelli and Tresoldi's piece-wise function is:\n",
    "$$\n",
    "I(PW)= \\sum_{q \\in P} f(x(q))\n",
    "$$\n",
    "\n",
    "Where $P$ is the set of all passes in a given period.\n",
    "\n",
    "In consideration of time, we will only be constructing the piece-wise function from Malucelli and Tresoldi and using its related index for the purposes of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38e1baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will calculate the Malucelli-Tresoldi Piecewise Index for the intervals.\n",
    "\n",
    "# define new dataframes\n",
    "data_0 = pd.DataFrame() \n",
    "\n",
    "# define a function for the conditions of the piecewise function.\n",
    "# Our default parameters will be equal to the simplist function. Labeled as 01 by Malucelli and Tresoldi.\n",
    "def piecewise(X, a=0, b=0, g=0, d=1, t_1=120, t_2=120, t_3=240):\n",
    "    if X < -t_1:\n",
    "        return -a*X\n",
    "    elif X >= -t_1 and X < t_2:\n",
    "        return 0\n",
    "    elif X >= t_2 and X < t_3:\n",
    "        return b*X\n",
    "    elif X >= t_3:\n",
    "        return g*X+d\n",
    "\n",
    "# apply our piecewise function\n",
    "li = []\n",
    "for row in data.itertuples():\n",
    "    gap = row.gap\n",
    "    pw = piecewise(gap)\n",
    "    li.append(pw)\n",
    "data['PW'] = li\n",
    "\n",
    "# Create a list of columns for data_1 to drop later.\n",
    "li = data.columns.to_list()\n",
    "li.pop(li.index('timecentral'))\n",
    "\n",
    "# Sum our 'PW' values by our intervals to get our index\n",
    "data_0 = data.resample(freq, on='timecentral').sum()\n",
    "li.pop(li.index('PW')) # We want to keep the 'PW' column\n",
    "data_0.drop(li, axis=1, inplace=True)\n",
    "data_0.rename(columns={'PW':'I_PW'}, inplace=True)\n",
    "\n",
    "# Concatenate I_PW values to master dataframe and delete intermediate variables from memory\n",
    "master_df = pd.concat([master_df, data_0], axis=1)\n",
    "del data_0, li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8575196d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>headwaysecs</th>\n",
       "      <th>scheduledheadwaysecs</th>\n",
       "      <th>HR</th>\n",
       "      <th>HS</th>\n",
       "      <th>PR</th>\n",
       "      <th>I_PW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timecentral</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-19 00:00:00</th>\n",
       "      <td>30.293191</td>\n",
       "      <td>-97.737928</td>\n",
       "      <td>1687.359947</td>\n",
       "      <td>1693.142857</td>\n",
       "      <td>0.993644</td>\n",
       "      <td>0.735285</td>\n",
       "      <td>0.993644</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 01:00:00</th>\n",
       "      <td>30.295484</td>\n",
       "      <td>-97.738471</td>\n",
       "      <td>1686.653455</td>\n",
       "      <td>1715.270608</td>\n",
       "      <td>0.980554</td>\n",
       "      <td>0.710113</td>\n",
       "      <td>1.019446</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 02:00:00</th>\n",
       "      <td>30.278059</td>\n",
       "      <td>-97.737004</td>\n",
       "      <td>1732.625760</td>\n",
       "      <td>1692.547033</td>\n",
       "      <td>0.979247</td>\n",
       "      <td>0.685338</td>\n",
       "      <td>0.979247</td>\n",
       "      <td>296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 03:00:00</th>\n",
       "      <td>30.279623</td>\n",
       "      <td>-97.735773</td>\n",
       "      <td>1741.818209</td>\n",
       "      <td>1710.132159</td>\n",
       "      <td>0.980398</td>\n",
       "      <td>0.717155</td>\n",
       "      <td>0.980398</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 19:00:00</th>\n",
       "      <td>30.291210</td>\n",
       "      <td>-97.732976</td>\n",
       "      <td>1465.227817</td>\n",
       "      <td>1405.872931</td>\n",
       "      <td>0.914681</td>\n",
       "      <td>0.476216</td>\n",
       "      <td>0.914681</td>\n",
       "      <td>5375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 20:00:00</th>\n",
       "      <td>30.292363</td>\n",
       "      <td>-97.732183</td>\n",
       "      <td>1667.768094</td>\n",
       "      <td>1610.051929</td>\n",
       "      <td>0.949510</td>\n",
       "      <td>0.579247</td>\n",
       "      <td>0.949510</td>\n",
       "      <td>4057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 21:00:00</th>\n",
       "      <td>30.292783</td>\n",
       "      <td>-97.734055</td>\n",
       "      <td>1752.594771</td>\n",
       "      <td>1702.955922</td>\n",
       "      <td>0.964070</td>\n",
       "      <td>0.653043</td>\n",
       "      <td>0.964070</td>\n",
       "      <td>4237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 22:00:00</th>\n",
       "      <td>30.292943</td>\n",
       "      <td>-97.735064</td>\n",
       "      <td>1697.509141</td>\n",
       "      <td>1664.296605</td>\n",
       "      <td>0.978953</td>\n",
       "      <td>0.691067</td>\n",
       "      <td>0.978953</td>\n",
       "      <td>3353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:00:00</th>\n",
       "      <td>30.290101</td>\n",
       "      <td>-97.735207</td>\n",
       "      <td>1702.841482</td>\n",
       "      <td>1637.555621</td>\n",
       "      <td>0.961262</td>\n",
       "      <td>0.625488</td>\n",
       "      <td>0.961262</td>\n",
       "      <td>2373.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           lat        lon  headwaysecs  scheduledheadwaysecs  \\\n",
       "timecentral                                                                    \n",
       "2022-06-19 00:00:00  30.293191 -97.737928  1687.359947           1693.142857   \n",
       "2022-06-19 01:00:00  30.295484 -97.738471  1686.653455           1715.270608   \n",
       "2022-06-19 02:00:00  30.278059 -97.737004  1732.625760           1692.547033   \n",
       "2022-06-19 03:00:00  30.279623 -97.735773  1741.818209           1710.132159   \n",
       "2022-06-19 04:00:00        NaN        NaN          NaN                   NaN   \n",
       "...                        ...        ...          ...                   ...   \n",
       "2022-06-25 19:00:00  30.291210 -97.732976  1465.227817           1405.872931   \n",
       "2022-06-25 20:00:00  30.292363 -97.732183  1667.768094           1610.051929   \n",
       "2022-06-25 21:00:00  30.292783 -97.734055  1752.594771           1702.955922   \n",
       "2022-06-25 22:00:00  30.292943 -97.735064  1697.509141           1664.296605   \n",
       "2022-06-25 23:00:00  30.290101 -97.735207  1702.841482           1637.555621   \n",
       "\n",
       "                           HR        HS        PR    I_PW  \n",
       "timecentral                                                \n",
       "2022-06-19 00:00:00  0.993644  0.735285  0.993644   279.0  \n",
       "2022-06-19 01:00:00  0.980554  0.710113  1.019446   132.0  \n",
       "2022-06-19 02:00:00  0.979247  0.685338  0.979247   296.0  \n",
       "2022-06-19 03:00:00  0.980398  0.717155  0.980398   107.0  \n",
       "2022-06-19 04:00:00       NaN       NaN       NaN     0.0  \n",
       "...                       ...       ...       ...     ...  \n",
       "2022-06-25 19:00:00  0.914681  0.476216  0.914681  5375.0  \n",
       "2022-06-25 20:00:00  0.949510  0.579247  0.949510  4057.0  \n",
       "2022-06-25 21:00:00  0.964070  0.653043  0.964070  4237.0  \n",
       "2022-06-25 22:00:00  0.978953  0.691067  0.978953  3353.0  \n",
       "2022-06-25 23:00:00  0.961262  0.625488  0.961262  2373.0  \n",
       "\n",
       "[168 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ef304",
   "metadata": {},
   "source": [
    "## Export Dataframe\n",
    "\n",
    "The last thing to do is export the dataframe for spatial analysis in ArcGIS Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a8b7898",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv(\"../01_New_Data/Python_Output/Vehicle_Disruption.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c419a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
